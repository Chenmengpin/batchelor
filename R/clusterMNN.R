#' Cluster-based MNN
#'
#' Perform MNN correction based on cluster centroids, 
#' using the corrected centroid coordinates to correct the per-cell expression values 
#' with a variable bandwidth Gaussian kernel.
#'
#' @inheritParams fastMNN
#' @param clusters A list of length equal to \code{...} containing the assigned cluster for each cell in each batch.
#' If \code{NULL}, this is generated by k-means clustering with centers equal to the root of the number of cells in each batch.
#' 
#' @return
#' For \code{clusterMNN}, 
#' a \linkS4class{SingleCellExperiment} containing per-cell expression values where each row is a gene and each column is a cell.
#' This has the same format as the output of \code{\link{fastMNN}} with the exception of the metadata.
#'
#' For \code{reducedClusterMNN}, 
#' a \linkS4class{DataFrame} is returned containing the corrected low-dimensional values.
#' This has the same format as the output of \code{\link{reducedMNN}} with the exception of the metadata.
#'
#' @details
#' These functions are motivated by the scenario where each batch has been clustered separately
#' (and each cluster has already been annotated with some meaningful biological state).
#' The aim is to perform the correction in a manner that is more likely to preserve these meaningful within-batch clusters.
#' This is achieved by performing the correction on the cluster centroids and then applying the changes to the per-cell values.
#' 
#' In \code{clusterMNN}, \code{\link{multiBatchPCA}} is called to obtain a low-dimensional representation,
#' and then \code{\link{reducedMNN}} is used to perform the correction on the cluster centroids.
#' Correction of each individual cell is done by applying a Gaussian kernel to the correction vectors for the centroids,
#' where the bandwidth is proportional to the distance between that cell and the centroid of its assigned cluster.
#' This yields a smooth correction function that avoids edge effects at cluster boundaries.
#' 
#' These functions are primarily intended to be used with some user-specified \code{clusters}.
#' However, if \code{clusters=NULL}, we will fill it in by running \code{\link{kmeans}} on the low-dimensional coordinates.
#' This mode can considered as a direct substitute for \code{\link{fastMNN}};
#' the main difference is that \code{clusterMNN} is generally more conservative due to the default \code{k=1} (see comments below),
#' which preserves more within-batch structure but may lead to incomplete merging across batches.
#'
#' @section Theoretical comments:
#' The default setting of \code{k=1} is important as it guarantees that each cluster has no more than one match in another batch.
#' This reduces the risk of inadvertently merging together different clusters from the same batch.
#' By comparison, higher values of \code{k} may result in many-to-one mappings between batches
#' such that the correction will implicitly force different clusters together.
#'
#' The relative performance of \code{clusterMNN} over \code{\link{fastMNN}} as an unsupervised correction method depends - as one might expect - on the clustering:
#' \itemize{
#' \item Unlike \code{\link{fastMNN}}, \code{clusterMNN} solves the kissing problem by working with cluster centroids.
#' This avoids MNNs forming only on the surface of the mass of cells because that mass is collapsed to a single point.
#' However, this only works if the clustering is not so granular that it captures variation along the batch vetor.
#' \item  \code{clusterMNN} may also be more robust thatn \code{\link{fastMNN}} to outlier cells.
#' Such cells form undesirable MNNs with larger clusters of cells in other batches, 
#' preventing those clusters from merging with each other (see Lun, 2019).
#' Provided that these cells do not form separate clusters, their effect on \code{clusterMNN} is mitigated.
#' }
#' 
#' @author Aaron Lun
#'
#' @references
#' Lun ATL (2019).
#' A discussion of the known failure points of the fastMNN algorithm.
#' \url{https://marionilab.github.io/FurtherMNN2018/theory/failure.html}
#' @export
#' @importFrom scater .bpNotSharedOrUp
#' @importFrom BiocParallel bpstart bpstop
clusterMNN <- function(..., batch=NULL, restrict=NULL, clusters=NULL, d=50, weights=NULL,
    k=1, prop.k=0, ndist=3, merge.order=NULL, auto.merge=FALSE, min.batch.skip=0,
    subset.row=NULL, correct.all=FALSE, assay.type="logcounts",
    BSPARAM=IrlbaParam(deferred=TRUE), BNPARAM=KmknnParam(), BPPARAM=SerialParam()) 
{
    # Setting up the parallelization environment.
    if (.bpNotSharedOrUp(BPPARAM)) {
        bpstart(BPPARAM)
        on.exit(bpstop(BPPARAM), add=TRUE)
    }

    pca <- multiBatchPCA(..., batch=batch, BSPARAM=BSPARAM, BPPARAM=BPPARAM, 
        d=d, weights=weights, subset.row=subset.row, get.all.genes=correct.all)

    .cluster_mnn(pca, batch=batch, restrict=restrict, clusters=clusters,
        k=k, prop.k=prop.k, ndist=ndist, 
        merge.order=merge.order, auto.merge=auto.merge, min.batch.skip=min.batch.skip,
        BNPARAM=BNPARAM, BPPARAM=BPPARAM)
}

#' @export
#' @rdname clusterMNN
reducedClusterMNN <- function(..., batch=NULL, restrict=NULL, clusters=NULL, 
    k=1, prop.k=0, ndist=3, merge.order=NULL, auto.merge=FALSE, min.batch.skip=0,
    BNPARAM=KmknnParam(), BPPARAM=SerialParam()) 
{
    batches <- list(...)
    checkBatchConsistency(batches, cells.in.columns=FALSE)
    if (length(batches)==1L) {
        pca <- divideIntoBatches(batches[[1]], batch=batch, byrow=FALSE)
    } else {
        pca <- batches
    }

    .cluster_mnn(batches, batch=batch, restrict=restrict, clusters=clusters,
        k=k, prop.k=prop.k, ndist=ndist, 
        merge.order=merge.order, auto.merge=auto.merge, min.batch.skip=min.batch.skip,
        BNPARAM=BNPARAM, BPPARAM=BPPARAM)
}


#' @importFrom utils tail
#' @importFrom BiocNeighbors queryKNN
#' @importFrom S4Vectors DataFrame
.cluster_mnn <- function(batches, batch, restrict, clusters, ..., BNPARAM, BPPARAM) {
    # Checking input clusters.
    if (is.null(clusters)) {
        clusters <- .generate_kmeans_clusters(batches, restrict, BNPARAM, BPPARAM)
    } else if (!is.null(batch)) {
        clusters <- split(clusters, batch)
    } else {
        if (length(clusters)!=length(batches)) {
            stop("'...' and 'clusters' should be of the same length")
        }
        for (i in seq_along(clusters)) {
            if (nrow(batches[[i]])!=length(clusters[[i]])) {
                stop("corresponding entries of '...' and 'clusters' should have the same number of cells")
            }
        }
    }

    # Performing MNN on the cluster centroids, which is relatively easy.
    clusters <- lapply(clusters, as.character)
    centers <- vector("list", length(clusters))
    for (i in seq_along(batches)) {
        if (!is.null(curres <- restrict[[i]])) {
            cls <- clusters[[i]][curres]
            mat <- rowsum(batches[[i]][curres,,drop=FALSE], cls)
        } else {
            cls <- clusters[[i]]
            mat <- rowsum(batches[[i]], cls)
        }
        centers[[i]] <- mat/as.numeric(table(cls)[rownames(mat)])
    }

    output <- do.call(reducedMNN, c(centers, list(..., BNPARAM=BNPARAM, BPPARAM=BPPARAM)))

    # Smoothing the correction applied to the clusters and applying it to the cells.
    # Each cell's smoothing bandwidth is set to the distance from its assigned cluster.
    last <- 0L
    renamed <- vector("list", length(batches))

    for (i in seq_along(batches)) {
        curbatch <- batches[[i]]
        curcenter <- centers[[i]]
        indices <- last + seq_len(nrow(curcenter))
        last <- tail(indices, 1L)

        corrected <- output$corrected[indices,,drop=FALSE]
        delta <- corrected - curcenter
#        closest <- queryKNN(query=curbatch, X=curcenter, k=1, BNPARAM=BNPARAM, 
#            BPPARAM=BPPARAM, get.distance=FALSE)$index
        sigma <- queryKNN(query=curbatch, X=curcenter, k=1, BNPARAM=BNPARAM, 
            BPPARAM=BPPARAM, get.distance=TRUE)$distance[,1]

        adj <- 0
        total <- 0
        tbatch <- t(curbatch)
        for (j in seq_len(nrow(curcenter))) {
            d2 <- colSums((tbatch - curcenter[j,])^2)
            weight <- exp(- d2/sigma^2) # no need to worry about underflow, there is always a weight of exp(-1) somewhere.
            adj <- adj + outer(weight, delta[j,])
            total <- total + weight
        }
    
        batches[[i]] <- batches[[i]] + adj/total
#        batches[[i]] <- batches[[i]] + delta[closest,,drop=FALSE]
        renamed[[i]] <- rep(output$batch[indices[1]], nrow(curbatch))
    }

    DataFrame(corrected=I(do.call(rbind, batches)), batch=unlist(renamed))
}

#' @importFrom stats kmeans
#' @importFrom BiocNeighbors queryKNN
.generate_kmeans_clusters <- function(batches, restrict, BNPARAM, BPPARAM) {
    clusters <- list()
    for (i in seq_along(batches)) {
        curbatch <- batches[[i]]
        if (is.null(curres <- restrict[[i]])) {
            clusters[[i]] <- kmeans(curbatch, centers=sqrt(nrow(curbatch)))$cluster

        } else {
            subbatch <- curbatch[curres,,drop=FALSE]
            k.out <- kmeans(subbatch, centers=sqrt(nrow(subbatch)))
            full.out <- integer(nrow(curbatch))
            full.out[curres] <- k.out$cluster

            leftovers <- !seq_len(nrow(curbatch)) %in% curres
            closest <- queryKNN(X=k.out$centers, query=curbatch[leftovers,,drop=FALSE], k=1, 
                BNPARAM=BNPARAM, BPPARAM=BPPARAM, get.distance=FALSE)$index
            full.out[leftovers] <- closest
            clusters[[i]] <- full.out
        }
    }
    clusters
}
